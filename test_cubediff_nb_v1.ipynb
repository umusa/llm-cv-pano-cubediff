{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pipeline\n",
    "from cubediff_pipeline import create_cubediff_pipeline, generate_panorama\n",
    "\n",
    "# Create the pipeline with the correct parameters\n",
    "pipeline = create_cubediff_pipeline(\n",
    "    pretrained_model_id=\"runwayml/stable-diffusion-v1-5\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Generate a panorama\n",
    "result = generate_panorama(\n",
    "    prompt=\"A beautiful mountain landscape at sunset with a lake in the foreground\",\n",
    "    negative_prompt=\"blurry, ugly, distorted, low quality, low resolution, text, watermark\",\n",
    "    num_inference_steps=100,  # More steps for better quality\n",
    "    guidance_scale=8.5,\n",
    "    seed=42,\n",
    "    pipeline=pipeline\n",
    ")\n",
    "\n",
    "# Display the panorama\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plt.imshow(result[\"panorama\"])\n",
    "plt.title(f\"Generated Panorama\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Display individual cubemap faces\n",
    "face_names = ['Front', 'Right', 'Back', 'Left', 'Top', 'Bottom']\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (face, name) in enumerate(zip(result[\"faces\"], face_names)):\n",
    "    axes[i].imshow(face)\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from diffusers import DDIMScheduler, PNDMScheduler, DPMSolverMultistepScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cubediff_models import load_sd_components, convert_attention_modules\n",
    "from cubediff_utils import add_cubemap_positional_encodings, cubemap_to_equirect\n",
    "from cubediff_inference import CubeDiffInference\n",
    "from cubediff_pipeline import create_cubediff_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model components\n",
    "vae, text_encoder, tokenizer, unet = load_sd_components(\n",
    "    model_id=\"runwayml/stable-diffusion-v1-5\", \n",
    "    use_sync_gn=True\n",
    ")\n",
    "\n",
    "# Convert UNet's attention to inflated attention\n",
    "print(\"Converting UNet attention modules...\")\n",
    "unet = convert_attention_modules(unet)\n",
    "\n",
    "# Set up scheduler (PNDM for better quality)\n",
    "scheduler = PNDMScheduler.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    subfolder=\"scheduler\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline with enhanced settings\n",
    "# pipeline = create_cubediff_pipeline(\n",
    "#     pretrained_model_id=\"runwayml/stable-diffusion-v1-5\",\n",
    "#     scheduler_type=\"pndm\",  # Try \"pndm\", \"ddim\", or \"dpm\"\n",
    "#     use_enhanced_attention=True,\n",
    "#     device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# )\n",
    "\n",
    "# Create inference pipeline\n",
    "pipeline = CubeDiffInference(\n",
    "    vae=vae,\n",
    "    unet=unet,\n",
    "    text_encoder=text_encoder,\n",
    "    tokenizer=tokenizer,\n",
    "    scheduler=scheduler,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for generation with reduced memory usage\n",
    "prompt = \"A beautiful mountain landscape at sunset with a lake in the foreground\"\n",
    "negative_prompt = \"blurry, ugly, distorted, low quality, low resolution, bad anatomy, worst quality, unrealistic, text, watermark\"\n",
    "\n",
    "# Generate the panorama with memory-optimized settings\n",
    "result = pipeline.generate(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    height=512,  # Reduced from 768 to save memory\n",
    "    width=512,   # Reduced from 768 to save memory\n",
    "    num_inference_steps=75,  # Reduced from 100 to save memory\n",
    "    guidance_scale=9.0,\n",
    "    seed=42,\n",
    "    return_faces=True,\n",
    "    use_pos_encodings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated panorama\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plt.imshow(result[\"panorama\"])\n",
    "plt.title(f\"Generated Panorama: {prompt}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display individual cubemap faces\n",
    "face_names = ['Front', 'Right', 'Back', 'Left', 'Top', 'Bottom']\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (face, name) in enumerate(zip(result[\"faces\"], face_names)):\n",
    "    axes[i].imshow(face)\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with different parameters\n",
    "result_alt = pipeline.generate(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    height=768,\n",
    "    width=768,\n",
    "    num_inference_steps=75,  # Fewer steps for faster generation\n",
    "    guidance_scale=8.0,  # Different guidance scale\n",
    "    seed=123,  # Different seed\n",
    "    return_faces=True,\n",
    "    use_pos_encodings=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the alternative panorama\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plt.imshow(result_alt[\"panorama\"])\n",
    "plt.title(f\"Alternative Panorama: {prompt}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

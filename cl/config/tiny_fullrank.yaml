#  configure for fine-tuning of CubeDiff “tiny” model – 700 panoramas
# --- data --------------------------------------------------

dataset : "/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/cubediff_train.tar"
val_dataset: "/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/cubediff_val.tar"
batch_size:    2         # per GPU process 

# bump these to drive more CPU‐side throughput
num_workers:   1         

# --- optimisation -----------------------------------------
gradient_accum_steps: 4   
learning_rate:      2.0e-5  # lower peak LR for stable convergence, drop LR to bring update size back in line with what I had under ε-MSE (≈ 0.14–0.48). 
boundary_weight:    0.3 # got from debug information, original 1.0 but it dominated the total loss of mse_loss and perc_loss
perceptual_weight:  0.5

# --- training ---------------------------------------------
num_epochs:         20 
log_loss_every_n_steps:    1 
log_lora_every_n_steps: 1 
eval_every_n_samples: 50 
sample_every_n_steps:  100
save_every_n_steps:   500
eval_every_n_steps:   500
warmup_steps:  1000
plateau_ratio: 0

# --- misc --------------------------------------------------
use_wandb:          false
output_dir:         "outputs/cubediff_tiny_lora"
seed:               1337

# --- quantization / inflation tweaks ----------------------
skip_weight_copy: false  # if no copy (old latent weights & biases from UNet2DConditionModel), the panorama will be noisy colors even trained for 12k+ data samples
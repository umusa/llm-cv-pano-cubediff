{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-5-20 run it on \"python 3\" base env on ins-gl-pt-gpu24-efe8b01-j4-0env-pdp with L4 GPU\n",
    "\n",
    "# ====================================\n",
    "# 2025-5-13 run it on \"python 3\" base env on ins-gl-pt-gpu24-2c94136-3env-j4-l4-test-1 with 1 L4 GPU\n",
    "# run on a single GPU notebook cell you can point the same script directly\n",
    "\n",
    "# steps of updating data to remvove mask channel:\n",
    "# 1. run this script (/Users/jinxuding/Downloads/CV/cubediff/implementation/llm-cv-pano-cubediff/cl/data/polyhaven/build_tiny_set.py) \n",
    "#   to generate the new data\n",
    "# 2. run this shell script (/Users/jinxuding/Downloads/CV/cubediff/implementation/llm-cv-pano-cubediff/cl/training/create_tar.sh) \n",
    "#   to create the tar file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d828dab-f0b4-4fd5-8f3b-2570f8bb260b",
   "metadata": {},
   "source": [
    "# download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0804d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"/home/jupyter/mluser/git/llm-cv-pano-cubediff\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/nvidia/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "# Set torch compile backend\n",
    "os.environ[\"TORCH_COMPILE_BACKEND\"] = \"inductor\"\n",
    "os.environ[\"ACCELERATE_CONFIG_FILE\"]=\"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/config/accelerate_config.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ebf5ff-ee54-43fe-9455-0ab4f9743dba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-20 16:51:40,044] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:cl.data.polyhaven.cubemap_builder:PyTorch GPU acceleration available: NVIDIA L4\n",
      "INFO:cl.data.polyhaven.cubemap_builder:Using 94 CPU cores for parallel processing\n",
      "INFO:cl.data.polyhaven.api_client:Fetching list of HDRIs from Polyhaven API (limit: 700)...\n",
      "ERROR:cl.data.polyhaven.api_client:Error accessing Polyhaven API: HTTPSConnectionPool(host='api.polyhaven.com', port=443): Max retries exceeded with url: /assets (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c88cca0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Using fallback HDRI list\n",
      "INFO:cl.data.polyhaven.api_client:Downloading 15 new HDRIs out of 15 total\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/wide_street_01_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/wide_street_01_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c88eb60>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/kloppenheim_06_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/kloppenheim_06_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c88f430>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/kloppenheim_02_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/kloppenheim_02_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c88fd00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/rural_asphalt_road_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/rural_asphalt_road_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d4610>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/wide_street_01_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d5000>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/wide_street_01.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/kloppenheim_06_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d5900>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/kloppenheim_06.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/kloppenheim_02_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d6230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/kloppenheim_02.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/rural_asphalt_road_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d6b90>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/rural_asphalt_road.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/small_rural_road_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/small_rural_road_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d4a00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/abandoned_slaughterhouse_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/abandoned_slaughterhouse_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d73a0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/abandoned_tank_farm_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/abandoned_tank_farm_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d7b20>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/abandoned_factory_canteen_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/abandoned_factory_canteen_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58704370>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/small_rural_road_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58704c10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/small_rural_road.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/abandoned_slaughterhouse_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d6950>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/abandoned_slaughterhouse.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/abandoned_tank_farm_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d5e70>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/abandoned_tank_farm.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/abandoned_factory_canteen_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d5840>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/abandoned_factory_canteen.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/air_museum_entrance_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/air_museum_entrance_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58705c00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/aerodynamics_workshop_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/aerodynamics_workshop_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb587053f0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/alpine_cabin_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/alpine_cabin_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d65c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/alps_field_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/alps_field_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58704a60>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/air_museum_entrance_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb587063e0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/air_museum_entrance.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/aerodynamics_workshop_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58706b30>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/aerodynamics_workshop.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/alpine_cabin_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d52a0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/alpine_cabin.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/alps_field_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d5b70>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/alps_field.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/autumn_forest_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/autumn_forest_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb587073a0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/artist_workshop_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/artist_workshop_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58707bb0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/autumn_park_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/autumn_park_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb587303a0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "^C\n",
      "Process ForkProcess-31:\n",
      "Process ForkProcess-29:\n",
      "Process ForkProcess-22:\n",
      "Process ForkProcess-25:\n",
      "Process ForkProcess-24:\n",
      "Process ForkProcess-32:\n",
      "Process ForkProcess-30:\n",
      "Process ForkProcess-21:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-23:\n",
      "Process ForkProcess-27:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-26:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-2:\n",
      "Downloading HDRIs:  80%|███████████████████▏    | 12/15 [18:48<04:42, 94.07s/it]\n",
      "Process ForkProcess-28:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# 2025-5-20 copied data from \"merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/data\"\n",
    "# so no need to download and generate tar files.\n",
    "# # after installing packages\n",
    "# !python /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/polyhaven/build_tiny_set.py \\\n",
    "#       --out /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny \n",
    "#       --skip_download \\\n",
    "#       --skip_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f3ea6-dc31-4b21-b683-7d158f7a6213",
   "metadata": {},
   "source": [
    "# set up env "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ee89a-cf89-495e-8611-9cf4ab08e832",
   "metadata": {},
   "source": [
    "# update .pt files for latent states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb9b473-b456-49bb-95b2-11612700c7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-20 16:49:17,902] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: /home/jupyter/.triton/autotune: No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/training/../data/polyhaven/build_tiny_set.py\", line 36, in <module>\n",
      "    from cl.data.polyhaven.api_client import list_hdris, parallel_download\n",
      "ModuleNotFoundError: No module named 'cl'\n"
     ]
    }
   ],
   "source": [
    "# 2025-5-14 update train dataset for only \".pt\" files (the latent states of cubemaps faces) because it was added \"mask chanel\"\n",
    "# which cause tensor mismatch in the downstreams; the \"mask channle\" should be added in \"forwad()\" on model side rather than on data side.\n",
    "# !python ../data/polyhaven/build_tiny_set.py \\\n",
    "#       --out /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny \\\n",
    "#       --skip_download \\\n",
    "#       --skip_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab6261-8973-446b-a73f-35a6270d5872",
   "metadata": {},
   "source": [
    "# generate py files that will be used to create train and val tar files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5a60c-e4df-4c17-a175-e0f5654dadb4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 2025-5-14 generate py files that will be used to create train and val tar files\n",
    "# run \"create_tar.sh\" to generate :\n",
    "# make_train_val_tars.py\n",
    "# verify_simple.py\n",
    "# load_webdataset.py\n",
    "# process_cubediff_data.sh\n",
    "\n",
    "# root@af45057ae158:~/mluser/git/llm-cv-pano-cubediff/cl/training# ./create_tar.sh \n",
    "# ===== Fixing WebDataset Issues for CubeDiff Data =====\n",
    "# ===== Setup Complete =====\n",
    "# To process your CubeDiff data, run:\n",
    "#   ./process_cubediff_data.sh\n",
    "\n",
    "# This script will:\n",
    "# 1. Create the WebDataset tar files with proper formatting\n",
    "# 2. Verify the structure of the tar files\n",
    "# 3. Load the data and create visualizations\n",
    "\n",
    "# The key fix is using standard WebDataset naming conventions\n",
    "# for the files within the tar, which resolves the AssertionError.\n",
    "# root@af45057ae158:~/mluser/git/llm-cv-pano-cubediff/cl/training# ls -lh *.sh\n",
    "# -rwxr-xr-x 1 root root  19K Apr 26 17:02 create_tar.sh\n",
    "# -rwxr-xr-x 1 root root 2.4K May 15 05:15 process_cubediff_data.sh\n",
    "# -rwxr-xr-x 1 root root  581 Apr 28 06:47 run_train.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07e0eb-c8b0-425e-bc95-0db3783a9697",
   "metadata": {},
   "source": [
    "# generate tar files for train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c380b0-7c5e-4ff9-9030-149e351e7f60",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 2025-5-14\n",
    "# root@af45057ae158:~/mluser/git/llm-cv-pano-cubediff/cl/training# ./process_cubediff_data.sh\n",
    "# =====================================\n",
    "# CubeDiff Data Processing Pipeline\n",
    "# =====================================\n",
    "# Data locations:\n",
    "# - Latents: ../data/dataspace/polyhaven_tiny/latents\n",
    "# - Captions: ../data/dataspace/polyhaven_tiny/raw/captions.json\n",
    "# - Output train tar: ../data/dataspace/polyhaven_tiny/cubediff_train.tar\n",
    "# - Output val tar: ../data/dataspace/polyhaven_tiny/cubediff_val.tar\n",
    "# - Validation fraction: 0.071\n",
    "# =====================================\n",
    "\n",
    "\n",
    "# ===== STEP 1: Creating WebDataset tar files =====\n",
    "# Loaded 700 captions\n",
    "# First 3 caption keys: ['abandoned_bakery', 'abandoned_church', 'abandoned_construction']\n",
    "# Found 700 latent files\n",
    "# First 3 latent files: ['../data/dataspace/polyhaven_tiny/latents/abandoned_bakery.pt', '../data/dataspace/polyhaven_tiny/latents/abandoned_church.pt', '../data/dataspace/polyhaven_tiny/latents/abandoned_construction.pt']\n",
    "# Extracted 700 IDs\n",
    "# First 3 IDs: ['abandoned_bakery', 'abandoned_church', 'abandoned_construction']\n",
    "# ID abandoned_bakery exists in captions: True\n",
    "# ID abandoned_church exists in captions: True\n",
    "# ID abandoned_construction exists in captions: True\n",
    "# Split into 651 train and 49 val\n",
    "# Processing train set...\n",
    "# Processed 50/651 in train\n",
    "# Processed 100/651 in train\n",
    "# Processed 150/651 in train\n",
    "# Processed 200/651 in train\n",
    "# Processed 250/651 in train\n",
    "# Processed 300/651 in train\n",
    "# Processed 350/651 in train\n",
    "# Processed 400/651 in train\n",
    "# Processed 450/651 in train\n",
    "# Processed 500/651 in train\n",
    "# Processed 550/651 in train\n",
    "# Processed 600/651 in train\n",
    "# Processed 650/651 in train\n",
    "# ✓ train: Processed 651 samples (0 missing)\n",
    "# ✓ train: Created ../data/dataspace/polyhaven_tiny/cubediff_train.tar (1464.9 MB)\n",
    "# Processing val set...\n",
    "# ✓ val: Processed 49 samples (0 missing)\n",
    "# ✓ val: Created ../data/dataspace/polyhaven_tiny/cubediff_val.tar (110.5 MB)\n",
    "\n",
    "# Tar file sizes:\n",
    "# - Training tar: 1.5G\n",
    "# - Validation tar: 111M\n",
    "\n",
    "\n",
    "# ===== STEP 2: Simple Tar Verification =====\n",
    "# Verifying ../data/dataspace/polyhaven_tiny/cubediff_train.tar...\n",
    "# File size: 1464.9 MB\n",
    "# /opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
    "#   warnings.warn(\n",
    "\n",
    "# Sample 1:\n",
    "#   Keys: ['__key__', '__url__', 'quarry_01_puresky.pt', '__local_path__', 'quarry_01_puresky.txt']\n",
    "#   ID: quarry_01_puresky\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'quarry 01 puresky'\n",
    "\n",
    "# Sample 2:\n",
    "#   Keys: ['__key__', '__url__', 'gray_pier.pt', '__local_path__', 'gray_pier.txt']\n",
    "#   ID: gray_pier\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'gray pier'\n",
    "\n",
    "# Sample 3:\n",
    "#   Keys: ['__key__', '__url__', 'neuer_zollhof.pt', '__local_path__', 'neuer_zollhof.txt']\n",
    "#   ID: neuer_zollhof\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'neuer zollhof'\n",
    "\n",
    "# Found 651 samples with keys: {'drackenstein_quarry.txt', 'georgentor.txt', 'small_empty_room_2.pt', 'nagoya_wall_path.txt', 'rostock_arches.pt', 'crosswalk.pt', 'colosseum.txt', 'cyclorama_hard_light.txt', 'childrens_hospital.txt', 'snowy_cemetery.pt', 'little_paris_under_tower.txt', 'je_gray_park.txt', 'pump_station.txt', 'abandoned_church.pt', 'sunset_fairway.txt', 'evening_road_01.txt', 'between_bridges.pt', 'qwantani_late_afternoon.pt', 'rogland_sunset.pt', 'fouriesburg_mountain_lookout.txt', 'palermo_square.pt', 'beach_parking.pt', 'lakeside_sunrise.txt', 'autumn_hockey.txt', 'leibstadt.pt', 'boma.txt', 'skylit_garage.pt', 'dikhololo_night.pt', 'resting_place.txt', 'fireplace.txt', 'blue_grotto.pt', 'ehingen_hillside.pt', 'lenong_1.pt', 'abandoned_bakery.pt', 'lapa.txt', 'hotel_room.pt', 'autumn_ground.pt', 'qwantani_patio.txt', 'quarry_02.txt', 'overcast_soil_2.pt', 'qwantani_dawn.pt', 'snowy_forest_path_02.txt', 'geislingen_an_der_steige.txt', 'abandoned_tank_farm_04.txt', 'kiara_7_late-afternoon.pt', 'modern_buildings_night.txt', 'gothic_manor_01.pt', 'kiara_7_late-afternoon.txt', 'large_corridor.txt', 'signal_hill_dawn.txt', 'small_empty_room_2.txt', 'carpentry_shop_01.txt', 'sunset_forest.txt', 'konzerthaus.pt', 'orlando_stadium.txt', 'satara_night_no_lamps.pt', 'brown_photostudio_02.txt', 'boma.pt', 'noga.txt', 'studio_garden.txt', 'indoor_pool.pt', 'kloppenheim_06_puresky.pt', 'kloofendal_43d_clear_puresky.txt', 'syferfontein_0d_clear.pt', 'modern_buildings.txt', 'quarry_01_puresky.pt', 'mutianyu.pt', 'misty_farm_road.txt', 'blaubeuren_hillside.txt', 'distribution_board.txt', 'sculpture_exhibition.txt', 'minedump_flats.txt', 'abandoned_tank_farm_01.pt', 'stream.pt', 'konigsallee.pt', 'mealie_road.pt', 'alps_field.pt', 'sunflowers.pt', 'snow_field_2.txt', 'castle_zavelstein_cellar.txt', 'red_wall.pt', 'sunset_fairway.pt', 'lakes.pt', 'hotel_rooftop_balcony.pt', 'etzwihl.pt', 'dark_autumn_forest.txt', 'qwantani_dusk_2.txt', 'storeroom.txt', 'felsenlabyrinth.pt', 'missile_launch_facility_01.txt', 'approaching_storm.txt', 'snow_field_2_puresky.pt', 'cannon.txt', 'provence_studio.txt', 'autumn_hockey.pt', 'cape_hill.txt', 'lenong_3.txt', 'docklands_01.pt', 'rural_graffiti_tower.pt', 'residential_garden.txt', 'kloppenheim_01.txt', 'qwantani_moon_noon.pt', 'outdoor_workshop.txt', 'nature_reserve_forest.txt', 'quarry_04_puresky.pt', 'simons_town_rocks.txt', 'kloppenheim_03.pt', 'pedestrian_overpass.pt', 'snowy_field.pt', 'abandoned_hopper_terminal_04.pt', 'limpopo_golf_course.txt', 'dresden_square.pt', 'small_harbour_sunset.pt', 'lakeside_dawn.pt', 'red_hill_curve.txt', 'hikers_cave.pt', 'reading_room.txt', 'small_empty_room_1.pt', 'snow_field_puresky.pt', 'aloe_farm_shade_house.pt', 'kloofendal_38d_partly_cloudy_puresky.pt', 'pond.pt', 'furry_clouds.pt', 'construction_yard.pt', 'river_walk_1.pt', 'abandoned_factory_canteen_02.txt', 'dresden_station_night.pt', 'hayloft.pt', 'driving_school.txt', 'pillars.pt', 'moonlit_golf.txt', 'derelict_underpass.txt', 'between_bridges.txt', 'small_harbor_01.txt', 'rosendal_park_sunset.pt', 'qwantani_puresky.pt', 'mosaic_tunnel.txt', 'christmas_photo_studio_03.txt', 'resting_place.pt', 'small_cathedral.pt', 'brown_photostudio_01.txt', 'belfast_open_field.txt', 'secluded_beach.txt', 'machine_shop_03.pt', 'missile_launch_facility_01.pt', 'summer_stage_02.txt', 'kart_club.txt', 'ostrich_road.txt', 'cyclorama_hard_light.pt', 'sandsloot.txt', 'abandoned_tank_farm_05.txt', 'machine_shop_03.txt', 'small_rural_road.pt', 'aft_lounge.txt', 'snowy_forest.txt', 'solitude_night.txt', 'museumplein.txt', 'phone_shop.pt', 'portland_landing_pad.pt', 'eilenriede_park.pt', 'studio_small_06.pt', 'kiara_5_noon.pt', 'reichstag_1.txt', 'sabie_tent.pt', 'quarry_cloudy.txt', 'dikhololo_sunset.txt', 'rustig_koppie.txt', 'old_room.pt', 'reinforced_concrete_01.pt', 'shady_patch.txt', 'kloofendal_misty_morning.pt', 'belfast_sunset.pt', 'rustig_koppie.pt', 'old_apartments_walkway.txt', 'stuttgart_suburbs.pt', 'roof_garden.pt', 'montorfano.txt', 'abandoned_pathway.txt', 'brown_photostudio_06.pt', 'dry_hay_field.txt', 'rathaus.txt', 'music_hall_02.pt', 'pizzo_pernice.txt', 'gray_pier.txt', 'misty_dawn.txt', 'kloppenheim_02_puresky.pt', 'snowy_forest_path_02.pt', 'quarry_02.pt', 'night_bridge.txt', 'forgotten_miniland.txt', 'noga.pt', 'bell_park_dawn.pt', 'kloetzle_blei.txt', 'clarens_night_01.pt', 'glass_passage.txt', 'peppermint_powerplant.txt', 'dresden_moat.txt', 'lakeside.pt', 'ehingen_hillside.txt', 'anniversary_lounge.pt', 'garage.txt', 'circus_arena.pt', 'small_empty_room_3.pt', 'cambridge.txt', 'kiara_2_sunrise.txt', 'factory_yard.pt', 'childrens_hospital.pt', 'piazza_bologni.pt', 'qwantani.txt', 'small_empty_room_3.txt', 'pretoria_gardens.txt', 'aristea_wreck_puresky.txt', 'modern_bathroom.pt', 'bismarckturm_hillside.txt', 'canary_wharf.pt', 'museum_of_history.pt', 'fouriesburg_mountain_midday.pt', 'overcast_soil_puresky.txt', 'peppermint_powerplant_2.txt', 'delta_2.txt', 'san_giuseppe_bridge.pt', 'industrial_sunset_02.pt', 'blue_lagoon_night.txt', 'small_cave.txt', 'small_rural_road_02.pt', 'golden_bay.txt', 'rocky_ridge_puresky.pt', 'flower_road.txt', 'mosaic_tunnel.pt', 'surgery.pt', 'old_bus_depot.pt', 'roofless_ruins.pt', 'factory_yard.txt', 'royal_esplanade.pt', 'spaichingen_hill.pt', 'empty_warehouse_01.txt', 'hamburg_canal.txt', 'passendorf_snow.txt', 'dam_road.txt', 'promenade_de_vidy.txt', 'pedestrian_overpass.txt', 'kiara_3_morning.pt', 'red_hill_cloudy.txt', 'goegap.txt', 'freight_station.txt', 'old_bus_depot.txt', 'kiara_9_dusk.txt', 'small_rural_road_02.txt', 'pump_station.pt', 'countrytrax_midday.txt', 'fouriesburg_mountain_cloudy.txt', 'derelict_overpass.pt', 'gamrig.txt', 'blouberg_sunrise_1.txt', 'qwantani_mid_morning.pt', 'farm_field_puresky.txt', 'blaubeuren_night.pt', 'rathaus.pt', 'misty_pines.pt', 'red_hill_cloudy.pt', 'old_tree_in_city_park.txt', 'shanghai_riverside.txt', 'autumn_road.txt', 'cinema_hall.txt', 'sunset_forest.pt', 'golf_course_sunrise.pt', 'greenwich_park.txt', 'old_quarry_gerlingen.pt', 'shudu_lake.pt', 'industrial_pipe_and_valve_02.txt', 'ballawley_park.txt', 'near_the_river_02.pt', 'farm_field_puresky.pt', 'lythwood_lounge.txt', 'green_sanctuary.txt', 'kloofendal_43d_clear.pt', 'kloppenheim_05_puresky.pt', 'sepulchral_chapel_basement.txt', 'autumn_field.txt', 'bergen.pt', 'hospital_room.txt', 'autumn_forest_04.pt', 'christmas_photo_studio_06.txt', 'herkulessaulen.txt', 'mossy_forest.pt', 'blender_institute.pt', 'modern_buildings_2.txt', 'simons_town_rocks.pt', 'sunflowers.txt', 'rocky_ridge.txt', 'schadowplatz.pt', 'museum_of_ethnography.pt', 'rosendal_park_sunset.txt', 'moulton_falls_train_tunnel_east.txt', 'abandoned_slipway.txt', 'metro_noord.pt', 'rustig_koppie_puresky.txt', 'kloppenheim_02.txt', 'qwantani_moon_noon.txt', 'abandoned_workshop_02.txt', 'simons_town_road.txt', 'suburban_parking_area.pt', 'abandoned_hopper_terminal_02.txt', 'sterkspruit_falls.txt', 'fouriesburg_mountain_lookout_2.txt', 'old_apartments_walkway.pt', 'aerodynamics_workshop.txt', 'gear_store.pt', 'quattro_canti.txt', 'evening_road_01.pt', 'neuer_zollhof.txt', 'creepy_bathroom.pt', 'street_lamp.pt', 'park_bench.pt', 'abandoned_tank_farm_05.pt', 'small_rural_road.txt', 'peppermint_powerplant_2.pt', 'hanger_exterior_cloudy.pt', 'netball_court.pt', 'harties.pt', '__url__', 'blue_grotto.txt', 'autoshop_01.pt', 'sandsloot.pt', 'kiara_8_sunset.pt', 'solitude_night.pt', 'pillars.txt', 'harvest.txt', 'lebombo.pt', 'courtyard.txt', 'rogland_overcast.pt', 'cloud_layers.txt', 'monte_scherbelino.txt', 'spaichingen_hill.txt', 'binnenalster.txt', 'golden_gate_hills.txt', 'kloppenheim_05.pt', 'satara_night_no_lamps.txt', 'cloudy_vondelpark.txt', 'countrytrax_midday.pt', 'museumplein.pt', 'kloofendal_38d_partly_cloudy.txt', 'autumn_forest_03.txt', 'dark_autumn_forest.pt', 'aloe_farm_shade_house.txt', 'dam_bridge.txt', 'autumn_forest_02.pt', 'artist_workshop.pt', 'syferfontein_18d_clear_puresky.txt', 'kloofendal_48d_partly_cloudy_puresky.pt', 'monbachtal_riverbank.pt', 'studio_small_08.pt', 'aviation_museum_hill.pt', 'dikhololo_sunset.pt', 'abandoned_tiled_room.pt', 'palermo_square.txt', 'sterkspruit_falls.pt', 'hamburg_hbf.pt', 'rooftop_night.pt', 'pizzo_pernice_puresky.txt', 'abandoned_waterworks.txt', 'bismarckturm.txt', 'resting_place_2.pt', 'greenwich_park_02.pt', 'graveyard_pathways.txt', 'dry_hay_field.pt', 'industrial_sunset_puresky.pt', 'drakensberg_solitary_mountain.pt', 'soliltude.pt', 'lilienstein.pt', 'leibstadt.txt', 'greenwich_park_03.pt', 'round_platform.txt', 'bethnal_green_entrance.pt', 'sunny_vondelpark.txt', 'qwantani_night.pt', 'dam_bridge.pt', 'monks_forest.pt', 'neurathen_rock_castle.pt', 'carpentry_shop_01.pt', 'rostock_arches.txt', 'lenong_3.pt', 'ox_bridge_morning.pt', 'modern_bathroom.txt', 'qwantani.pt', 'signal_hill_sunrise.txt', 'autumn_meadow.txt', 'mirrored_hall.txt', 'kloppenheim_07_puresky.txt', 'klippad_dawn_1.pt', 'qwantani_dusk_2.pt', 'abandoned_church.txt', 'dry_cracked_lake.txt', 'quattro_canti.pt', 'cinema_lobby.pt', 'bloem_hill_01.txt', 'rotes_rathaus.txt', 'country_club.pt', 'lythwood_room.pt', 'green_point_park.txt', 'cedar_bridge.txt', 'rotes_rathaus.pt', 'rogland_overcast.txt', 'distribution_board.pt', 'mpumalanga_veld_puresky.txt', 'abandoned_tank_farm_03.txt', 'acoustical_shell.txt', 'dam_wall.txt', 'sisulu.txt', 'air_museum_playground.pt', 'abandoned_hopper_terminal_02.pt', 'konzerthaus.txt', 'abandoned_construction.txt', 'docklands_02.pt', 'fouriesburg_mountain_cloudy.pt', 'schachen_forest.txt', 'hochsal_forest.pt', 'sunset_jhbcentral.txt', 'autumn_meadow.pt', 'pylons.txt', 'quarry_04_puresky.txt', 'autumn_forest_01.txt', 'beach_cloudy_bridge.pt', 'aviation_museum.pt', 'snowy_cemetery.txt', 'burnt_warehouse.txt', 'harties_cliff_view.pt', 'lakeside_night.txt', 'anniversary_lounge.txt', 'dalkey_view.txt', 'old_hall.txt', 'ehingen_hillside_02.txt', 'rostock_laage_airport.txt', 'rooitou_park.txt', 'neon_photostudio.pt', 'subway_entrance.pt', 'leadenhall_market.txt', 'hospital_room_2.txt', 'moulton_falls_train_tunnel_east.pt', 'red_hill_straight.pt', 'mealie_road.txt', 'crystal_falls.txt', 'derelict_highway_midday.pt', 'hikers_cave.txt', 'dry_orchard_meadow.pt', 'brick_factory_01.txt', 'rural_winter_roadside.pt', 'dry_cracked_lake.pt', 'snow_field.txt', 'abandoned_hall_01.txt', 'small_hangar_02.txt', 'future_parking.pt', 'cabin.txt', 'brown_photostudio_07.txt', 'frozen_lake.txt', 'studio_small_08.txt', 'hall_of_mammals.txt', 'potsdamer_platz.pt', 'narrow_moonlit_road.txt', 'river_walk_2.pt', 'derelict_highway_noon.pt', 'horn-koppe_snow.pt', 'farm_sunset.txt', 'green_point_park.pt', 'music_hall_01.pt', 'lythwood_terrace.pt', 'christmas_photo_studio_02.pt', 'combination_room.txt', 'amphitheatre_zanzibar_fort.pt', 'abandoned_parking.pt', 'lakeside_dawn.txt', 'abandoned_hopper_terminal_03.txt', 'rosendal_park_sunset_puresky.pt', 'flamingo_pan.txt', 'skukuza_golf.txt', 'killesberg_park.pt', 'qwantani_noon.pt', 'potsdamer_platz.txt', 'champagne_castle_1.pt', 'cannon.pt', 'cayley_lookout.txt', 'spruit_dawn.txt', 'oberer_kuhberg.txt', 'binnenalster.pt', 'blue_lagoon.txt', 'lenong_1.txt', 'hangar_interior.pt', 'steinbach_field.pt', 'school_hall.pt', 'small_harbor_01.pt', 'lauter_waterfall.pt', 'greenwich_park.pt', 'night_bridge.pt', 'drackenstein_quarry_puresky.txt', 'snowy_hillside.pt', 'blau_river.pt', 'stream.txt', 'kloofendal_misty_morning.txt', 'poly_haven_studio.txt', 'lakeside_sunrise.pt', 'brown_photostudio_07.pt', 'small_harbor_02.pt', 'pylons.pt', 'flower_hillside.pt', 'derelict_highway_midday.txt', 'beach_cloudy_bridge.txt', 'eilenriede_labyrinth.txt', 'nkuhlu.txt', 'montorfano.pt', 'old_tree_in_city_park.pt', 'misty_farm_road.pt', 'ox_bridge_morning.txt', 'buikslotermeerplein.pt', 'abandoned_greenhouse.pt', 'limehouse.pt', 'small_empty_house.pt', 'forgotten_miniland.pt', 'kloofendal_28d_misty_puresky.txt', 'evening_meadow.pt', 'leadenhall_market.pt', 'entrance_hall.pt', 'ruckenkreuz.txt', 'summer_stage_02.pt', 'rosendal_plains_2.pt', 'moulton_station_train_tunnel_west.pt', 'chapel_day.txt', 'autumn_forest_02.txt', 'satara_night.pt', 'empty_workshop.txt', 'comfy_cafe.pt', 'reichstag_1.pt', 'hamburg_hbf.txt', 'kart_club.pt', 'outdoor_umbrellas.pt', 'evening_road_01_puresky.txt', 'delta_2.pt', 'suburban_field_02.pt', 'lonely_road_afternoon_puresky.pt', 'sisulu.pt', 'blaubeuren_outskirts.pt', 'brown_photostudio_06.txt', 'dresden_moat.pt', 'laufenurg_church.pt', 'alps_field.txt', 'castle_zavelstein_cellar.pt', 'fort_schanskop_morning.txt', 'small_empty_room_4.txt', 'clarens_midday.pt', 'museum_of_history.txt', 'monbachtal_riverbank.txt', 'autumn_field_puresky.txt', 'hanger_exterior_cloudy.txt', 'lythwood_field.txt', 'frozen_lake.pt', 'quarry_01.txt', 'suburban_field_02.txt', 'herkulessaulen.pt', 'epping_forest_02.pt', 'orlando_stadium.pt', 'lythwood_room.txt', 'industrial_workshop_foundry.txt', 'aristea_wreck.pt', 'aviation_museum.txt', 'stuttgart_hillside.txt', 'bambanani_sunset.pt', 'signal_hill_sunrise.pt', 'drachenfels_cellar.txt', 'kloofendal_38d_partly_cloudy.pt', 'snowy_field.txt', 'small_hangar_02.pt', 'sunflowers_puresky.txt', 'abandoned_pathway.pt', 'learner_park.pt', 'kloppenheim_07_puresky.pt', 'dresden_square.txt', 'christmas_photo_studio_01.pt', 'derelict_highway_noon.txt', 'studio_small_07.txt', 'snowy_park_01.pt', 'gym_01.txt', 'kloofendal_43d_clear.txt', 'soliltude.txt', 'petit_port.txt', 'dry_orchard_meadow.txt', 'reinforced_concrete_02.txt', 'kiara_interior.pt', 'petit_port.pt', 'drachenfels_cellar.pt', 'learner_park.txt', 'hospital_room.pt', 'reinforced_concrete_02.pt', 'belfast_farmhouse.txt', 'lakeside_night.pt', 'rocky_ridge.pt', 'indoor_pool.txt', 'residential_garden.pt', 'bloem_train_track_cloudy.pt', 'greenwich_park_03.txt', 'kloofendal_48d_partly_cloudy.txt', 'canary_wharf.txt', 'altanka.pt', 'studio_small_03.pt', 'lauter_waterfall.txt', 'quarry_03.txt', 'studio_small_04.txt', 'derelict_underpass.pt', 'machine_shop_02.pt', 'basement_boxing_ring.pt', 'cayley_lookout.pt', 'kiara_1_dawn.txt', 'interior_construction.txt', 'storeroom.pt', 'citrus_orchard.txt', 'spiaggia_di_mondello.pt', 'billiard_hall.pt', 'epping_forest_01.txt', 'studio_small_05.txt', 'gothic_manor_01.txt', 'studio_small_06.txt', 'abandoned_hopper_terminal_03.pt', 'snow_field.pt', 'combination_room.pt', 'quarry_01_puresky.txt', 'epping_forest_02.txt', 'hotel_room.txt', 'secluded_beach.pt', 'qwantani_sunrise.pt', 'borghese_gardens.pt', 'rural_asphalt_road.pt', 'belvedere.txt', 'stierberg_sunrise.txt', 'mud_road_puresky.pt', 'monkstown_castle.pt', 'qwantani_morning.pt', 'phone_shop.txt', 'crystal_falls.pt', 'small_cave.pt', 'hausdorf_clear_sky.txt', 'drakensberg_solitary_mountain_puresky.pt', 'harvest.pt', 'rosendal_plains_2.txt', 'short_tunnel.txt', 'abandoned_tiled_room.txt', 'dry_meadow.txt', 'sunset_in_the_chalk_quarry.txt', 'kloofendal_38d_partly_cloudy_puresky.txt', 'golf_course_sunrise.txt', 'mall_parking_lot.txt', '__key__', 'blaubeuren_outskirts.txt', 'kloppenheim_04.txt', 'ballroom.pt', 'blue_photo_studio.txt', 'noon_grass.pt', 'citrus_orchard_road.txt', 'hall_of_finfish.pt', 'lago_disola.txt', 'docklands_02.txt', 'arboretum.txt', 'stuttgart_suburbs.txt', 'near_the_river_01.txt', 'artist_workshop.txt', 'bergen.txt', 'docklands_01.txt', 'rosendal_park_sunset_puresky.txt', 'modern_buildings.pt', 'overcast_soil.txt', 'outdoor_workshop.pt', 'machine_shop_01.txt', 'lake_pier.pt', 'parched_canal.pt', 'sunset_jhbcentral.pt', 'photo_studio_01.txt', 'studio_small_03.txt', 'music_hall_02.txt', 'monks_forest.txt', 'rosendal_mountain_midmorning.txt', 'hamburg_canal.pt', 'modern_buildings_night.pt', 'missile_launch_facility_02.txt', 'cambridge.pt', 'stone_alley_03.txt', 'dresden_station_night.txt', 'lago_disola.pt', 'small_empty_room_4.pt', 'qwantani_sunset.pt', 'river_rocks.pt', 'drakensberg_solitary_mountain.txt', 'moonlit_golf.pt', 'abandoned_parking.txt', 'farm_field.pt', 'blouberg_sunrise_2.txt', 'hochsal_forest.txt', 'hall_of_mammals.pt', 'lot_01.pt', 'spree_bank.txt', 'kiara_9_dusk.pt', 'outdoor_umbrellas.txt', 'abandoned_factory_canteen_02.pt', 'autumn_park.pt', 'courtyard_night.pt', 'red_hill_straight.txt', 'studio_small_09.pt', 'abandoned_factory_canteen_01.txt', 'sepulchral_chapel_rotunda.pt', 'scythian_tombs_2.pt', 'dikhololo_night.txt', 'evening_meadow.txt', 'pretville_cinema.txt', 'kloppenheim_06.pt', 'railway_bridges.pt', 'steinbach_field.txt', 'klippad_sunrise_2.pt', 'squash_court.txt', 'snowy_forest_path_01.txt', 'roof_garden.txt', 'abandoned_tank_farm_02.pt', 'autumn_road.pt', 'phalzer_forest_01.txt', 'quarry_cloudy.pt', 'blouberg_sunrise_2.pt', 'abandoned_waterworks.pt', 'air_museum_playground.txt', 'small_workshop.pt', 'qwantani_puresky.txt', 'cape_hill.pt', 'stierberg_sunrise.pt', 'interior_construction.pt', 'blouberg_sunrise_1.pt', 'industrial_sunset_02_puresky.pt', 'syferfontein_0d_clear.txt', 'balcony.pt', 'dry_field.txt', 'irish_institute.txt', 'abandoned_games_room_02.txt', 'comfy_cafe.txt', 'scythian_tombs.pt', 'borghese_gardens.txt', 'modern_buildings_2.pt', 'derelict_overpass.txt', 'rural_crossroads.txt', 'studio_small_02.txt', 'kloofendal_28d_misty_puresky.pt', 'suburban_parking_area.txt', 'hilly_terrain_01_puresky.pt', 'cloudy_cliffside_road.txt', 'industrial_sunset.txt', 'horn-koppe_snow.txt', 'preller_drive.pt', 'pool.txt', 'qwantani_patio.pt', 'reinforced_concrete_01.txt', 'kiara_1_dawn.pt', 'bloem_train_track_cloudy.txt', 'netball_court.txt', 'neuer_zollhof.pt', 'autoshop_01.txt', 'belfast_sunset_puresky.txt', 'missile_launch_facility_03.txt', 'studio_small_02.pt', 'sepulchral_chapel_basement.pt', 'st_fagans_interior.txt', 'balcony.txt', 'rolling_hills.txt', 'lush_dirt_path.txt', 'epping_forest_01.pt', 'rural_asphalt_road.txt', 'concrete_tunnel.txt', 'kloppenheim_06.txt', 'flower_hillside.txt', 'farm_sunset.pt', 'kloppenheim_01.pt', 'forest_grove.txt', 'small_harbour_sunset.txt', 'lakeside.txt', 'minedump_flats.pt', 'kloofendal_43d_clear_puresky.pt', 'summer_stage_01.pt', 'en_suite.txt', 'je_gray_02.pt', 'preller_drive.txt', 'gum_trees.txt', 'circus_maximus_2.pt', 'abandoned_tank_farm_01.txt', 'narrow_moonlit_road.pt', 'st_peters_square_night.pt', 'large_corridor.pt', 'snowy_hillside.txt', 'aircraft_workshop_01.txt', 'hilly_terrain_01.pt', 'drakensberg_solitary_mountain_puresky.txt', 'little_paris_under_tower.pt', 'fouriesburg_mountain_midday.txt', 'pretville_street.txt', 'old_hall.pt', 'qwantani_sunset.txt', 'resting_place_2.txt', 'palermo_park.txt', 'surgery.txt', 'garden_nook.pt', 'arboretum.pt', 'shanghai_riverside.pt', 'lookout.txt', 'circus_maximus_1.pt', 'circus_maximus_1.txt', 'geislingen_an_der_steige.pt', 'dreifaltigkeitsberg.txt', 'birbeck_street_underpass.pt', 'forest_cave.txt', 'pretoria_gardens.pt', 'aristea_wreck_puresky.pt', 'de_balie.pt', 'construction_yard.txt', 'abandoned_bakery.txt', 'rocky_ridge_puresky.txt', 'cobblestone_street_night.txt', 'red_hill_curve.pt', 'lakes.txt', 'photo_studio_london_hall.txt', 'rooftop_night.txt', 'abandoned_slipway.pt', 'ostrich_road.pt', 'georgentor.pt', 'decor_shop.txt', 'summer_stage_01.txt', 'snow_field_2.pt', 'brown_photostudio_01.pt', 'monkstown_castle.txt', 'spruit_sunrise.pt', 'belfast_farmhouse.pt', 'parched_canal.txt', 'kloppenheim_02.pt', 'chapel_day.pt', 'mossy_forest.txt', 'eilenriede_park.txt', 'bismarckturm_hillside.pt', 'st_fagans_interior.pt', 'rural_winter_roadside.txt', 'rosendal_mountain_midmorning.pt', 'blue_lagoon_night.pt', 'evening_road_01_puresky.pt', 'dancing_hall.pt', 'killesberg_park.txt', 'garden_nook.txt', 'boiler_room.pt', 'bismarckturm.pt', 'abandoned_tank_farm_02.txt', 'ehingen_hillside_02.pt', 'street_lamp.txt', 'poly_haven_studio.pt', 'rogland_sunset.txt', 'dry_meadow.pt', 'hilly_terrain_01_puresky.txt', 'glencairn_expressway.pt', 'mud_road_puresky.txt', 'kiara_2_sunrise.pt', 'dusseldorf_bridge.pt', 'sunny_vondelpark.pt', 'abandoned_factory_canteen_01.pt', 'rural_crossroads.pt', 'kloppenheim_01_puresky.txt', 'klippad_sunrise_1.pt', 'railway_bridges.txt', 'small_cathedral_02.txt', 'industrial_sunset.pt', 'christmas_photo_studio_04.pt', 'goegap_road.txt', 'christmas_photo_studio_06.pt', 'courtyard.pt', 'muddy_autumn_forest.pt', 'piazza_bologni.txt', 'photo_studio_01.pt', 'pond_bridge_night.pt', 'drackenstein_quarry.pt', 'medieval_cafe.pt', 'blue_photo_studio.pt', 'marry_hall.txt', 'subway_entrance.txt', 'reading_room.pt', 'mpumalanga_veld_puresky.pt', 'kloppenheim_03_puresky.txt', 'burnt_warehouse.pt', 'abandoned_workshop.txt', 'scythian_tombs.txt', 'qwantani_afternoon.pt', 'ninomaru_teien.pt', 'rosendal_plains_1.pt', 'misty_pines.txt', 'colorful_studio.txt', 'pretville_cinema.pt', 'muddy_autumn_forest.txt', 'rooitou_park.pt', 'rhodes_memorial.pt', 'kiara_6_afternoon.txt', 'small_harbour_morning.txt', 'belfast_sunset.txt', 'small_hangar_01.txt', 'san_giuseppe_bridge.txt', 'small_workshop.txt', 'gum_trees.pt', 'bell_park_dawn.txt', 'st_peters_square_night.txt', 'abandoned_workshop_02.pt', 'partial_eclipse.pt', 'mutianyu.txt', 'industrial_sunset_02_puresky.txt', 'blaubeuren_church_square.txt', 'qwantani_noon.txt', 'creepy_bathroom.txt', 'royal_esplanade.txt', 'cloud_layers.pt', 'illovo_beach_balcony.pt', 'old_room.txt', 'bank_vault.txt', 'basement_boxing_ring.txt', 'kloppenheim_04.pt', 'dam_road.pt', 'noon_grass.txt', 'boiler_room.txt', 'metro_vijzelgracht.pt', 'kloppenheim_03_puresky.pt', 'hausdorf_clear_sky.pt', 'schachen_forest.pt', 'kloppenheim_02_puresky.txt', 'brown_photostudio_05.txt', 'fish_eagle_hill.pt', 'piazza_martin_lutero.pt', 'signal_hill_dawn.pt', 'railway_bridge_02.txt', 'autumn_forest_01.pt', 'simons_town_harbour.pt', 'qwantani_dusk_1.pt', 'mall_parking_lot.pt', 'brown_photostudio_03.txt', 'studio_small_09.txt', 'river_rocks.txt', 'spruit_sunrise.txt', 'cedar_bridge.pt', 'mpumalanga_veld.pt', 'birbeck_street_underpass.txt', 'immenstadter_horn.pt', 'champagne_castle_1.txt', 'autumn_park.txt', 'missile_launch_facility_02.pt', 'promenade_de_vidy.pt', 'kiara_5_noon.txt', 'illovo_beach_balcony.txt', 'meadow_2.pt', 'dam_wall.pt', 'rogland_moonlit_night.txt', 'je_gray_park.pt', 'stone_alley.pt', 'brown_photostudio_04.pt', 'snow_field_puresky.txt', 'clarens_night_01.txt', 'colorful_studio.pt', 'meadow.txt', 'chinese_garden.pt', 'simons_town_road.pt', 'sunset_in_the_chalk_quarry.pt', 'abandoned_tank_farm_03.pt', 'fireplace.pt', 'autumn_crossing.txt', 'kloetzle_blei.pt', 'pizzo_pernice.pt', 'pizzo_pernice_puresky.pt', 'future_parking.txt', 'art_studio.pt', 'art_studio.txt', 'autumn_forest_03.pt', 'christmas_photo_studio_03.pt', 'brick_factory_02.txt', 'aviation_museum_hill.txt', 'quarry_04.pt', 'schadowplatz.txt', 'auto_service.txt', 'partial_eclipse.txt', 'small_cathedral.txt', 'cinema_hall.pt', 'small_hangar_01.pt', 'nature_reserve_forest.pt', 'nagoya_wall_path.pt', 'oberer_kuhberg.pt', 'abandoned_hopper_terminal_04.txt', 'medieval_cafe.txt', 'approaching_storm.pt', 'marry_hall.pt', 'moonless_golf.txt', 'bank_vault.pt', 'sepulchral_chapel_rotunda.txt', 'monte_scherbelino.pt', 'pond_bridge_night.txt', 'snowy_park_01.txt', 'gamrig.pt', 'kloppenheim_03.txt', 'kloppenheim_01_puresky.pt', 'snowy_forest.pt', 'pump_house.txt', 'spiaggia_di_mondello.txt', 'qwantani_mid_morning.txt', 'qwantani_late_afternoon.txt', 'ouchy_pier.txt', 'christmas_photo_studio_01.txt', 'pump_house.pt', 'kloofendal_28d_misty.pt', 'industrial_pipe_and_valve_02.pt', 'kloofendal_misty_morning_puresky.pt', 'sunflowers_puresky.pt', 'studio_garden.pt', 'beach_parking.txt', 'kloofendal_28d_misty.txt', 'meadow_2.txt', 'piazza_martin_lutero.txt', 'studio_small_05.pt', 'railway_bridge_02.pt', 'bush_restaurant.pt', 'overcast_soil.pt', 'cliffside.txt', 'klippad_sunrise_2.txt', 'kloofendal_48d_partly_cloudy_puresky.txt', 'qwantani_moonrise.txt', 'near_the_river_02.txt', 'flamingo_pan.pt', 'shudu_lake.txt', 'pine_attic.pt', 'circus_maximus_2.txt', 'kiara_8_sunset.txt', 'freight_station.pt', 'moulton_station_train_tunnel_west.txt', 'dry_field.pt', 'limpopo_golf_course.pt', 'kiara_4_mid-morning.txt', 'stone_alley_02.pt', 'pine_attic.txt', 'cinema_lobby.txt', 'stone_alley.txt', 'spree_bank.pt', 'industrial_workshop_foundry.pt', 'fouriesburg_mountain_lookout_2.pt', 'orbita.pt', 'lapa.pt', 'dalkey_view.pt', 'je_gray_02.txt', 'ballroom.txt', 'blau_river.txt', 'christmas_photo_studio_02.txt', 'laufenurg_church.txt', 'pool.pt', 'suburban_field_01.txt', 'qwantani_sunrise.txt', 'cobblestone_street_night.pt', 'furry_clouds.txt', 'cave_wall.txt', 'museum_of_ethnography.txt', 'country_club.txt', 'stadium_01.pt', 'autumn_field_puresky.pt', 'irish_institute.pt', 'industrial_sunset_puresky.txt', 'music_hall_01.txt', 'dusseldorf_bridge.txt', 'kiara_interior.txt', 'colosseum.pt', 'blaubeuren_church_square.pt', 'golden_bay.pt', 'bush_restaurant.txt', 'chapmans_drive.pt', 'kloppenheim_05.txt', 'kloppenheim_05_puresky.txt', 'gear_store.txt', 'kloofendal_48d_partly_cloudy.pt', 'rural_landscape.pt', 'overcast_soil_puresky.pt', 'piazza_san_marco.pt', 'hall_of_finfish.txt', 'qwantani_morning.txt', 'etzwihl.txt', 'felsenlabyrinth.txt', 'hotel_rooftop_balcony.txt', 'brown_photostudio_03.pt', 'abandoned_games_room_01.txt', 'meadow.pt', 'snowy_forest_path_01.pt', 'overcast_soil_2.txt', 'brown_photostudio_05.pt', 'fish_hoek_beach.txt', 'klippad_dawn_1.txt', 'blaubeuren_night.txt', 'missile_launch_facility_03.pt', 'mud_road.txt', 'blue_lagoon.pt', 'abandoned_construction.pt', 'crosswalk.txt', 'small_cathedral_02.pt', 'empty_warehouse_01.pt', 'adams_place_bridge.pt', 'skate_park.pt', 'qwantani_night.txt', 'photo_studio_london_hall.pt', 'concrete_tunnel.pt', 'abandoned_greenhouse.txt', 'roofless_ruins.txt', 'aircraft_workshop_01.pt', 'aft_lounge.pt', 'lilienstein.txt', 'mirrored_hall.pt', 'rainforest_trail.txt', 'qwantani_dawn.txt', 'phalzer_forest_01.pt', 'kloofendal_overcast_puresky.pt', 'cloudy_cliffside_road.pt', 'stone_alley_02.txt', 'buikslotermeerplein.txt', 'rural_landscape.txt', 'gray_pier.pt', 'fish_hoek_beach.pt', 'park_bench.txt', 'harties_cliff_view.txt', 'harties.txt', 'cabin.pt', 'bethnal_green_entrance.txt', 'skukuza_golf.pt', 'driving_school.pt', 'aristea_wreck.txt', 'brick_factory_01.pt', 'palermo_park.pt', 'old_quarry_gerlingen.txt', 'rostock_laage_airport.pt', 'brown_photostudio_02.pt', 'belfast_open_field.pt', 'small_empty_house.txt', 'school_hall.txt', 'autumn_field.pt', 'adams_place_bridge.txt', 'industrial_sunset_02.txt', 'de_balie.txt', 'snow_field_2_puresky.txt', 'ballawley_park.pt', 'christmas_photo_studio_04.txt', 'limehouse.txt', 'kiara_6_afternoon.pt', 'brick_factory_02.pt', 'misty_dawn.pt', 'passendorf_snow.pt', 'abandoned_games_room_01.pt', 'pink_sunrise.txt', 'graffiti_shelter.pt', 'mud_road.pt', 'hayloft.txt', 'acoustical_shell.pt', 'pink_sunrise.pt', 'small_harbour_morning.pt', 'amphitheatre_zanzibar_fort.txt', 'spruit_dawn.pt', 'qwantani_moonrise.pt', 'short_tunnel.pt', 'parking_garage.pt', 'ahornsteig.pt', 'citrus_orchard.pt', 'garage.pt', 'konigsallee.txt', 'goegap_road.pt', 'lonely_road_afternoon_puresky.txt', 'blender_institute.txt', 'scythian_tombs_2.txt', 'provence_studio.pt', 'lot_01.txt', 'birchwood.txt', 'eilenriede_labyrinth.pt', 'orbita.txt', 'studio_small_04.pt', 'lythwood_field.pt', 'gym_01.pt', 'auto_service.pt', 'small_harbor_02.txt', 'photo_studio_broadway_hall.txt', 'lythwood_terrace.txt', 'glencairn_expressway.txt', 'ninomaru_teien.txt', 'lush_dirt_path.pt', 'neon_photostudio.txt', 'autumn_forest_04.txt', 'kiara_4_mid-morning.pt', 'red_wall.txt', 'aerodynamics_workshop.pt', 'rural_graffiti_tower.txt', 'studio_small_01.pt', '__local_path__', 'studio_small_07.pt', 'old_depot.txt', 'kloppenheim_06_puresky.txt', 'paul_lobe_haus.pt', 'machine_shop_02.txt', 'citrus_orchard_road.pt', 'old_depot.pt', 'bloem_hill_01.pt', 'fort_schanskop_morning.pt', 'hochsal_field.txt', 'golden_gate_hills.pt', 'pond.txt', 'bell_park_pier.pt', 'forest_cave.pt', 'clarens_midday.txt', 'mpumalanga_veld.txt', 'altanka.txt', 'belvedere.pt', 'quarry_03.pt', 'qwantani_afternoon.txt', 'small_empty_room_1.txt', 'bell_park_pier.txt', 'lookout.pt', 'cave_wall.pt', 'syferfontein_18d_clear_puresky.pt', 'courtyard_night.txt', 'chinese_garden.txt', 'fouriesburg_mountain_lookout.pt', 'goegap.pt', 'lythwood_lounge.pt', 'hochsal_field.pt', 'graveyard_pathways.pt', 'portland_landing_pad.txt', 'moonless_golf.pt', 'sculpture_exhibition.pt', 'piazza_san_marco.txt', 'green_sanctuary.pt', 'ruckenkreuz.pt', 'glass_passage.pt', 'immenstadter_horn.txt', 'lebombo.txt', 'shady_patch.pt', 'ahornsteig.txt', 'greenwich_park_02.txt', 'quarry_01.pt', 'pretville_street.pt', 'qwantani_dusk_1.txt', 'kloofendal_misty_morning_puresky.txt', 'drackenstein_quarry_puresky.pt', 'rhodes_memorial.txt', 'near_the_river_01.pt', 'squash_court.pt', 'stone_alley_03.pt', 'abandoned_workshop.pt', 'blaubeuren_hillside.pt', 'machine_shop_01.pt', 'birchwood.pt', 'farm_field.txt', 'metro_noord.txt', 'river_walk_1.txt', 'chapmans_drive.txt', 'nkuhlu.pt', 'metro_vijzelgracht.txt', 'skylit_garage.txt', 'flower_road.pt', 'hangar_interior.txt', 'empty_workshop.pt', 'rosendal_plains_1.txt', 'graffiti_shelter.txt', 'simons_town_harbour.txt', 'autumn_ground.txt', 'studio_small_01.txt', 'klippad_sunrise_1.txt', 'rolling_hills.pt', 'suburban_field_01.pt', 'skate_park.txt', 'quarry_04.txt', 'brown_photostudio_04.txt', 'autumn_crossing.pt', 'dreifaltigkeitsberg.pt', 'sabie_tent.txt', 'river_walk_2.txt', 'kloofendal_overcast_puresky.txt', 'billiard_hall.txt', 'lake_pier.txt', 'skidpan.pt', 'abandoned_games_room_02.pt', 'neurathen_rock_castle.txt', 'hilly_terrain_01.txt', 'ouchy_pier.pt', 'stadium_01.txt', 'cliffside.pt', 'stuttgart_hillside.pt', 'en_suite.pt', 'abandoned_tank_farm_04.pt', 'photo_studio_broadway_hall.pt', 'forest_grove.pt', 'decor_shop.pt', 'paul_lobe_haus.txt', 'belfast_sunset_puresky.pt', 'rainforest_trail.pt', 'round_platform.pt', 'abandoned_hall_01.pt', 'peppermint_powerplant.pt', 'kiara_3_morning.txt', 'fish_eagle_hill.txt', 'dancing_hall.txt', 'circus_arena.txt', 'rogland_moonlit_night.pt', 'parking_garage.txt', 'satara_night.txt', 'skidpan.txt', 'entrance_hall.txt', 'cloudy_vondelpark.pt', 'rustig_koppie_puresky.pt', 'bambanani_sunset.txt', 'hospital_room_2.pt'}\n",
    "# Verifying ../data/dataspace/polyhaven_tiny/cubediff_val.tar...\n",
    "# File size: 110.5 MB\n",
    "\n",
    "# Sample 1:\n",
    "#   Keys: ['__key__', '__url__', 'floral_tent.pt', '__local_path__', 'floral_tent.txt']\n",
    "#   ID: floral_tent\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'floral tent'\n",
    "\n",
    "# Sample 2:\n",
    "#   Keys: ['__key__', '__url__', 'empty_play_room.pt', '__local_path__', 'empty_play_room.txt']\n",
    "#   ID: empty_play_room\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'empty play room'\n",
    "\n",
    "# Sample 3:\n",
    "#   Keys: ['__key__', '__url__', 'little_paris_eiffel_tower.pt', '__local_path__', 'little_paris_eiffel_tower.txt']\n",
    "#   ID: little_paris_eiffel_tower\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'little paris eiffel tower'\n",
    "\n",
    "# Found 49 samples with keys: {'gothic_manor_02.pt', 'stone_pines.txt', 'empty_play_room.txt', 'lenong_2.pt', 'niederwihl_forest.txt', 'blinds.pt', 'solitude_interior.txt', 'bathroom.pt', 'straw_rolls_field_01.txt', 'syferfontein_0d_clear_puresky.txt', 'rogland_clear_night.txt', 'studio_country_hall.pt', 'abandoned_hopper_terminal_01.pt', 'scythian_tombs_puresky.pt', 'photo_studio_loft_hall.txt', 'evening_field.txt', 'empty_play_room.pt', 'blocky_photo_studio.pt', 'school_quad.pt', 'syferfontein_18d_clear.txt', 'floral_tent.pt', 'emmarentia.txt', 'concrete_tunnel_02.pt', 'kloppenheim_07.txt', 'castel_st_angelo_roof.pt', 'safari_sunset.txt', 'dirt_bike_track_01.txt', 'syferfontein_18d_clear.pt', 'carpentry_shop_02.pt', 'bathroom.txt', 'bloem_train_track_clear.pt', 'kloppenheim_07.pt', 'shanghai_bund.txt', 'kloofendal_overcast.pt', 'old_outdoor_theater.txt', 'cayley_interior.txt', 'hansaplatz.txt', 'gym_entrance.txt', 'northcliff.pt', 'straw_rolls_field_01.pt', 'clarens_night_02.pt', 'kloofendal_overcast.txt', 'carpentry_shop_02.txt', 'industrial_pipe_and_valve_01.txt', 'floral_tent.txt', 'dirt_bike_track_01.pt', 'rooftop_day.pt', 'lenong_2.txt', 'shanghai_bund.pt', 'lot_02.pt', 'blocky_photo_studio.txt', 'bloem_train_track_clear.txt', '__local_path__', 'emmarentia.pt', 'school_quad.txt', 'blinds.txt', 'christmas_photo_studio_05.pt', 'rooftop_day.txt', 'park_parking.txt', 'klippad_dawn_2.txt', 'stone_pines.pt', 'safari_sunset.pt', 'klippad_dawn_2.pt', 'cayley_interior.pt', 'industrial_pipe_and_valve_01.pt', 'old_outdoor_theater.pt', 'photo_studio_loft_hall.pt', 'forest_slope.txt', 'castel_st_angelo_roof.txt', 'little_paris_eiffel_tower.pt', 'lonely_road_afternoon.pt', 'concrete_tunnel_02.txt', 'christmas_photo_studio_07.pt', 'christmas_photo_studio_05.txt', 'palermo_sidewalk.pt', 'studio_country_hall.txt', 'park_parking.pt', 'scythian_tombs_puresky.txt', 'rogland_clear_night.pt', 'solitude_interior.pt', 'gothic_manor_02.txt', 'lot_02.txt', 'forest_slope.pt', 'northcliff.txt', 'snowy_hillside_02.txt', 'snowy_hillside_02.pt', 'palermo_sidewalk.txt', 'hilltop_construction.txt', 'gym_entrance.pt', 'lonely_road_afternoon.txt', 'hilltop_construction.pt', 'syferfontein_0d_clear_puresky.pt', 'niederwihl_forest.pt', 'evening_field.pt', 'little_paris_eiffel_tower.txt', 'hansaplatz.pt', '__url__', '__key__', 'abandoned_hopper_terminal_01.txt', 'clarens_night_02.txt', 'christmas_photo_studio_07.txt'}\n",
    "\n",
    "# ✅ Both tar files appear valid\n",
    "\n",
    "\n",
    "# ===== STEP 3: Dataset Loading and Visualization =====\n",
    "# Loading dataset from ../data/dataspace/polyhaven_tiny/cubediff_train.tar...\n",
    "# /opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
    "#   warnings.warn(\n",
    "\n",
    "# Batch 1:\n",
    "#   Batch size: 4\n",
    "#   Latent shape: torch.Size([4, 24, 64, 64])\n",
    "\n",
    "# Sample 1:\n",
    "#   ID: quarry_01_puresky\n",
    "#   Latent shape: torch.Size([24, 64, 64])\n",
    "#   Caption: quarry 01 puresky\n",
    "#   Error visualizing latent: Expected tensor with shape [6, C, H, W], got torch.Size([24, 64, 64])\n",
    "\n",
    "# Sample 2:\n",
    "#   ID: gray_pier\n",
    "#   Latent shape: torch.Size([24, 64, 64])\n",
    "#   Caption: gray pier\n",
    "#   Error visualizing latent: Expected tensor with shape [6, C, H, W], got torch.Size([24, 64, 64])\n",
    "\n",
    "# Sample 3:\n",
    "#   ID: neuer_zollhof\n",
    "#   Latent shape: torch.Size([24, 64, 64])\n",
    "#   Caption: neuer zollhof\n",
    "#   Error visualizing latent: Expected tensor with shape [6, C, H, W], got torch.Size([24, 64, 64])\n",
    "\n",
    "# Processed 3 samples from 1 batches\n",
    "\n",
    "\n",
    "# ===== VERIFICATION COMPLETE =====\n",
    "# If all verification steps passed, your CubeDiff data is ready for training!\n",
    "# Training tar: ../data/dataspace/polyhaven_tiny/cubediff_train.tar (1.5G)\n",
    "# Validation tar: ../data/dataspace/polyhaven_tiny/cubediff_val.tar (111M)\n",
    "# Sample visualizations: ./visualizations\n",
    "\n",
    "# ==================================================\n",
    "# root@af45057ae158:~/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny# ls -lh\n",
    "# total 2.4G\n",
    "# -rw-r--r-- 1 root root 1.5G May 15 05:15 cubediff_train.tar\n",
    "# -rw-r--r-- 1 root root 111M May 15 05:15 cubediff_val.tar\n",
    "# drwxr-xr-x 2 root root  36K May 15 05:01 latents\n",
    "# -rw-r--r-- 1 root root 735M Apr 26 17:02 old_cubediff_train_with_mask_channel_2025_5_13.tar\n",
    "# -rw-r--r-- 1 root root  56M Apr 26 17:02 old_cubediff_val_with_mask_channel_2025_5_13.tar\n",
    "# drwxr-xr-x 2 root root  36K Apr 24 20:33 old_latents\n",
    "# drwxr-xr-x 2 root root  36K Apr 25 04:32 old_latents_with_mask_channel_2025_5_13\n",
    "# drwxr-xr-x 6 root root 4.0K Apr 25 04:27 raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a403ecf-0307-4b61-ad87-1990a95a6bfe",
   "metadata": {},
   "source": [
    "# install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcdb6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
      "Collecting torch==2.1.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/03/f1/13137340776dd5d5bcfd2574c9c6dfcc7618285035cd77240496e5c1a79b/torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Collecting torchvision==0.16.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/da/ae/76bd3682465730dea7be21f36a8160a911a470de6f26228904f222e7fefe/torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting peft>=0.8.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/68/85/8e6ea3d1089f2b6de3c1cd34bbbd7560912af9d34b057be3b8b8fefe1da3/peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Collecting opencv-python==4.8.1.78\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/b7/8a/b2f7e1a434d56bf1d7570fc5941ace0847404e1032d7f1f0b8fed896568d/opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "Collecting opencv-contrib-python==4.8.1.78\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/32/9e/4dcc0bb70e3b365dc85b8f96c63e6a306653f7cc6ed061aa6cc7b2bddee7/opencv_contrib_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.8 MB)\n",
      "Collecting matplotlib==3.8.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/19/e5/a4ea514515f270224435c69359abb7a3d152ed31b9ee3ba5e63017461945/matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Collecting tqdm==4.66.1\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Collecting einops==0.7.0\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "Collecting xformers\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/45/d0/4ed66b2d46bef4373f106b58361364cbd8ce53c85e60c8ea57ea254887bb/xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl (31.5 MB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (11.0.0)\n",
      "Collecting openexr\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/bc/d1/5f08ac6a62c66c40a9e1bf60ea7618e9f4e31f2b01de532cfdb4bd06cb42/openexr-3.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/dd/5c/c139a7876099916879609372bfa513b7f1257f7f1a908b0bdc1c2328241b/opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "Collecting wandb\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f9/31/eeb2878b26566c04c3e9b8b20b3ec3c54a2be50535088d36a37c008e07a3/wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
      "Collecting bitsandbytes\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/07/b7/cb5ce4d1a382cf53c19ef06c5fc29e85f5e129b4da6527dd207d90a5b8ad/bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "Collecting webdataset\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/6e/e1/c1140ab6533668930895512ac5cbf07972fa41ebab275f5f5cdd432bc3c7/webdataset-0.2.111-py3-none-any.whl (85 kB)\n",
      "Collecting timm\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/6c/d0/179abca8b984b3deefd996f362b612c39da73b60f685921e6cd58b6125b4/timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "Collecting diffusers\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/e7/7a/f08f610cea8a3395ad3b4f586db23bedb43c68db6c3261145a15e7b63126/diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
      "Collecting huggingface_hub\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/33/c7/852d4473788cfd7d79b73951244b87a6d75fdac296c90aeb5e85dbb2fb5e/huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
      "Collecting accelerate\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f8/bb/be8146c196ad6e4dec78385d91e92591f8a433576c4e04c342a636fcd811/accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Collecting deepspeed\n",
      "  Using cached deepspeed-0.16.8-py3-none-any.whl\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (2024.12.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/b6/9f/c64c03f49d6fbc56196664d05dba14e3a561038a81a638eeb47f4d4cfd48/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/eb/d5/c68b1d2cdfcc59e72e8a5949a37ddb22ae6cade80cd4a57a84d4c8b55472/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/7e/00/6b218edd739ecfc60524e585ba8e6b00554dd908de2c9c66c1af3e44e18d/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/bc/1d/8de1e5c67099015c834315e333911273a8c6aaba78923dd1d1e25fc5f217/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/65/5b/cfaeebf25cd9fdec14338ccb16f6b2c4c7fa9163aefcf057d86b9cc248bb/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a4/05/23f8f38eec3d28e4915725b233c24d8f1a33cb6540a882f7b54be1befa02/nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/4d/22/91a8af421c8a8902dde76e6ef3db01b258af16c53d81e8c0d0dc13900a9e/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.2) (1.25.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (2.9.0.post0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2) (12.4.99)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft>=0.8.2) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft>=0.8.2) (6.0.2)\n",
      "Collecting transformers (from peft>=0.8.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a9/b6/5257d04ae327b44db31f15cce39e6020cc986333c715660b1315a9724d82/transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Collecting safetensors (from peft>=0.8.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a6/f8/dae3421624fcc87a89d42e1898a798bc7ff72c61f38973a65d60df8f124c/safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting xformers\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/55/4f/ef63f866ec7d3a23f78629604deaf379cd833fa4fd0cf7e6f8a77906f125/xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a1/44/7b27f60ec6f31f99cd5c2ee0553ab6c0bd7a289cc2abac076a859ddac143/xformers-0.0.29.post2-cp310-cp310-manylinux_2_28_x86_64.whl (44.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/28/1d/03356b31386a61162bccddf7fba6c792b4fe1159ad2af5f4b7879ce947ad/xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a4/63/cf772ebd81759ce93dbdbb6d0236092b8f570f90675d505dab2d560daab6/xformers-0.0.29-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/02/56/d1a86f2c4a5a80e1f4926eef1ba69d6eb77ae823d36da7860984ca0b3421/xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/07/6c/62ce963a51e7c400f3720e93b479ce4020b8447b4d1e8138ec460e21b9d3/xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/ca/24/3335df4d7c363188705be2808eb7e4bacfbfe23e3a4671c8f311236036d1/xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "INFO: pip is still looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/7e/c9/a93741c2cc29dd44f361c801dd7e48f0d27617bf3951459578f20c61f511/xformers-0.0.28-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/04/69/f084d27545d130a960abb73fc84ad99f5260b3d98b55eef5dd065068055c/xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/2b/20/2c00a2238e6b5cbad5ebc9cd6f60d6e5c28146a86fc02cfb9da3e14538db/xformers-0.0.27.post1-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/3e/10/ce0d6e314b38ce8c438c04f5efc1498c8e68e4d9928cd5a2c046fc4f0923/xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (164.1 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/32/e7/27003645ef99e7571fb6964cd2f39da3f1b3f3011aa00bb2d3ac9b790757/xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/5f/9b/f781a50d965717a2a2ea2c8d15e0f30deec8f9751a9874e850ba9ab0fadc/xformers-0.0.25.post1-cp310-cp310-manylinux2014_x86_64.whl (222.5 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/81/29/df65a2933a6a9acf19a90e0aef74b0bc69635bbe890204d5d03e7d89c85d/xformers-0.0.25-cp310-cp310-manylinux2014_x86_64.whl (222.5 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/78/c9/0cdbc2403666833302ab13f07b02b4556a5885b0542c7aa67f52d5ad0401/xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl (218.2 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f4/89/ce8e936d3e64b3b565c16312dd6446d54f6e485f864130702c6b3b3cbe7c/xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.8)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.10.19)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f0/e5/da07b0bd832cefd52d16f2b9bbbe31624d57552602c06631686b93ccb1bd/sentry_sdk-2.29.1-py2.py3-none-any.whl (341 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/67/2b/c3cbd4a4462c1143465d8c151f1d51bbfb418e60a96a754329d28d416575/setproctitle-1.3.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (75.6.0)\n",
      "Collecting braceexpand (from webdataset)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/fa/93/e8c04e80e82391a6e51f218ca49720f64236bc824e92152a2633b74cf7ab/braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (8.4.0)\n",
      "Collecting regex!=2019.12.17 (from diffusers)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f2/98/26d3830875b53071f1f0ae6d547f1d98e964dd29ad35cbf94439120bb67a/regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Collecting hjson (from deepspeed)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/1f/7f/13cd798d180af4bf4c0ceddeefba2b864a63c71645abc0308b768d67bb81/hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.1.0)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/eb/7a/455d2877fe6cf99886849c7f9755d897df32eaf3a0fba47b56e615f880f7/ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Collecting py-cpuinfo (from deepspeed)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/e0/a9/023730ba63db1e494a271cb018dcd361bd2c917ba7004c3e49d5daf795a2/py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting pydantic<3 (from wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/e7/12/46b65f3534d099349e38ef6ec98b1a5a81f42536d17e0ba382c28c67ba67/pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Requirement already satisfied: nvidia-ml-py in /opt/conda/lib/python3.10/site-packages (from deepspeed) (11.495.46)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/31/0d/c8f7593e6bc7066289bbc366f2235701dcbebcd1ff0ef8e64f6f239fb47d/pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/31/08/aa4fdfb71f7de5176385bd9e90852eaf6b5d622735020ad600f2bab54385/typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.2) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2) (1.3.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers->peft>=0.8.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/8a/63/38be071b0c8e06840bc6046991636bcb30c27f6bb1e670f4f4bc87cf49cc/tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Installing collected packages: py-cpuinfo, hjson, braceexpand, webdataset, typing-inspection, triton, tqdm, setproctitle, sentry-sdk, safetensors, regex, pydantic-core, openexr, opencv-python-headless, opencv-python, opencv-contrib-python, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, einops, docker-pycreds, annotated-types, pydantic, nvidia-cusolver-cu12, nvidia-cudnn-cu12, matplotlib, huggingface_hub, wandb, torch, tokenizers, diffusers, xformers, transformers, torchvision, deepspeed, bitsandbytes, accelerate, timm, peft\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.99\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.0.142\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.0.142:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.0.142\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.119\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.119:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.119\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.0.44\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.0.44:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.0.44\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.99\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.99\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.99\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.2.65\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.2.65:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.2.65\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.19\n",
      "    Uninstalling pydantic-1.10.19:\n",
      "      Successfully uninstalled pydantic-1.10.19\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.0.99\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.0.99:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.0.99\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.3\n",
      "    Uninstalling matplotlib-3.7.3:\n",
      "      Successfully uninstalled matplotlib-3.7.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0+cu124\n",
      "    Uninstalling torch-2.4.0+cu124:\n",
      "      Successfully uninstalled torch-2.4.0+cu124\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.19.0+cu124\n",
      "    Uninstalling torchvision-0.19.0+cu124:\n",
      "      Successfully uninstalled torchvision-0.19.0+cu124\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dataproc-jupyter-plugin 0.1.80 requires pydantic~=1.10.0, but you have pydantic 2.11.4 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires matplotlib<=3.7.3,>=3.2, but you have matplotlib 3.8.2 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.11.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.7.0 annotated-types-0.7.0 bitsandbytes-0.45.5 braceexpand-0.1.7 deepspeed-0.16.8 diffusers-0.33.1 docker-pycreds-0.4.0 einops-0.7.0 hjson-3.1.0 huggingface_hub-0.31.4 matplotlib-3.8.2 ninja-1.11.1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 opencv-contrib-python-4.8.1.78 opencv-python-4.8.1.78 opencv-python-headless-4.11.0.86 openexr-3.3.3 peft-0.15.2 py-cpuinfo-9.0.0 pydantic-2.11.4 pydantic-core-2.33.2 regex-2024.11.6 safetensors-0.5.3 sentry-sdk-2.29.1 setproctitle-1.3.6 timm-1.0.15 tokenizers-0.21.1 torch-2.1.2 torchvision-0.16.2 tqdm-4.66.1 transformers-4.51.3 triton-2.1.0 typing-inspection-0.4.0 wandb-0.19.11 webdataset-0.2.111 xformers-0.0.23.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Found existing installation: torch-xla 2.4.0\n",
      "Uninstalling torch-xla-2.4.0:\n",
      "  Successfully uninstalled torch-xla-2.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.1.2 torchvision==0.16.2 \"peft>=0.8.2\" \\\n",
    "     opencv-python==4.8.1.78 opencv-contrib-python==4.8.1.78 matplotlib==3.8.2 tqdm==4.66.1 einops==0.7.0 \\\n",
    "     opencv-python xformers requests pillow openexr opencv-python-headless wandb \\\n",
    "     bitsandbytes webdataset timm diffusers huggingface_hub accelerate deepspeed \\\n",
    "     -i https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
    "\n",
    "!pip uninstall torch-xla -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d571efa-7e9b-49c2-8e8d-0087f7dd2876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate                               1.7.0\n",
      "diffusers                                0.33.1\n",
      "torch                                    2.1.2\n",
      "torchvision                              0.16.2\n",
      "transformers                             4.51.3\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep \"acc\\|torch\\|diff\\|trans\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6707650-1bce-4be4-b97c-ba7347a997a3",
   "metadata": {},
   "source": [
    "# config shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c56498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate more memory for shm\n",
    "!sudo mount -o remount,size=32G /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8186ccc3-fcc2-4502-aba0-00981bc0d8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         193G   94G  100G  49% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "shm              32G     0   32G   0% /dev/shm\n",
      "/dev/nvme0n2     98G   29G   70G  29% /home/jupyter\n",
      "/dev/nvme0n1p1  193G   94G  100G  49% /usr/local/nvidia/bin\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468e32c-6ee6-429a-8b84-45cf0470fc3d",
   "metadata": {},
   "source": [
    "# check models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e734c9a1-75e2-4d97-b3f9-dafb2e29bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16K\n",
      "drwxr-xr-x 6 root root 4.0K May 20 18:34 models--openai--clip-vit-base-patch32\n",
      "drwxr-xr-x 6 root root 4.0K May 20 18:34 models--runwayml--stable-diffusion-v1-5\n",
      "-rw-r--r-- 1 root root    1 May 20 18:34 version.txt\n",
      "-rw-r--r-- 1 root root    1 May 20 18:34 version_diffusers_cache.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c50c239b-fa7e-441b-b5f7-63581e131d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 528M\n",
      "-rw-r--r-- 1 root root 528M May 20 19:41 vgg16-397923af.pth\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/torch/hub/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e39fe6-9d56-4755-a0b0-0a999f18a8d5",
   "metadata": {},
   "source": [
    "# run training\n",
    "### copied HF/hub and torch.hub from last VM to this VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0b3de-be24-4ab5-af06-9ad9720cf324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-5-20 copied hf hub models to gcs and then copied them back to the target\n",
    "# gsutil -m cp -r \\\n",
    "#   ~/.cache/huggingface/hub \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/\n",
    "\n",
    "# on target VM:\n",
    "# mkdir -p ~/.cache/huggingface/hub\n",
    "# gsutil -m cp -r \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/* \\\n",
    "#   ~/.cache/huggingface/hub/\n",
    "\n",
    "# on source vm\n",
    "# copy torch/hub to the gcs and then to target vm\n",
    "# gsutil -m cp -r \\\n",
    "#   ~/.cache/torch/hub \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/torch_hub/\n",
    "\n",
    "# Copying file:///home/jupyter/.cache/torch/hub/checkpoints/vgg16-397923af.pth [Content-Type=application/octet-stream]...\n",
    "# ==> NOTE: You are uploading one or more large file(s), which would run          \n",
    "# significantly faster if you enable parallel composite uploads. This\n",
    "# feature can be enabled by editing the\n",
    "# \"parallel_composite_upload_threshold\" value in your .boto\n",
    "# configuration file. However, note that if you do this large files will\n",
    "# be uploaded as `composite objects\n",
    "# <https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
    "# means that any user who downloads such objects will need to have a\n",
    "# compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
    "# without a compiled crcmod, computing checksums on composite objects is\n",
    "# so slow that gsutil disables downloads of composite objects.\n",
    "\n",
    "# | [1/1 files][527.8 MiB/527.8 MiB] 100% Done                                    \n",
    "# Operation completed over 1 objects/527.8 MiB.  \n",
    "\n",
    "# on target VM:\n",
    "# mkdir -p ~/.cache/torch/hub\n",
    "# gsutil -m cp -r \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/torch_hub/hub/* \\\n",
    "#   ~/.cache/torch/hub/\n",
    "\n",
    "# Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/torch_hub/hub/checkpoints/vgg16-397923af.pth...\n",
    "# - [1/1 files][527.8 MiB/527.8 MiB] 100% Done                                    \n",
    "# Operation completed over 1 objects/527.8 MiB.             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716bf35b-8d9a-40b9-9c8b-e5885d854e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-5-20 after copying the models, this should work well.\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "# MAX_LEN  = tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29bc6b6b-fda4-40a7-8bbe-46d80b17f369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e8545d-310f-4e2f-8204-ef3df3f2d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"/home/jupyter/mluser/git/llm-cv-pano-cubediff\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/nvidia/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "# Set torch compile backend\n",
    "os.environ[\"TORCH_COMPILE_BACKEND\"] = \"inductor\"\n",
    "os.environ[\"ACCELERATE_CONFIG_FILE\"]=\"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/config/accelerate_config.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ddf3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCELERATE_CONFIG_FILE=\"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/config/accelerate_config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56703ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.09it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.05it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.06it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  1.98it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.07it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.05it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.03it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.00it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  1.82it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:02<00:00,  3.27it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:02<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file $ACCELERATE_CONFIG_FILE train_cubediff.py --cfg ../config/tiny_fullrank.yaml > cubediff_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd72ad-8edb-4c75-ae03-c2ee462f8ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

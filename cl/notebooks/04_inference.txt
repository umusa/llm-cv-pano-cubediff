{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CubeDiff: Inference and Evaluation\n",
    "\n",
    "This notebook demonstrates the inference pipeline for CubeDiff and evaluates the results:\n",
    "\n",
    "1. Load trained model\n",
    "2. Generate panoramas from text prompts\n",
    "3. Generate panoramas from single images\n",
    "4. Visualize and evaluate the results\n",
    "5. Compare with baseline methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "# Add parent directory to path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import custom modules\n",
    "from inference.pipeline import CubeDiffPipeline\n",
    "from data.preprocessing import equirect_to_cubemap, cubemap_to_equirect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "pretrained_model_name = \"runwayml/stable-diffusion-v1-5\"\n",
    "checkpoint_path = \"../outputs/cubediff_mini/final_model/model.pt\"\n",
    "\n",
    "# For demonstration, if we don't have a trained model yet, we'll use the base model\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(\"Trained model not found, using base Stable Diffusion model.\")\n",
    "    checkpoint_path = None\n",
    "else:\n",
    "    print(f\"Using trained model from {checkpoint_path}\")\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = CubeDiffPipeline(\n",
    "    pretrained_model_name=pretrained_model_name,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Panoramas from Text Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test prompts\n",
    "test_prompts = [\n",
    "    \"A beautiful sunset over a mountain range, with vibrant orange and purple sky\",\n",
    "    \"A cozy living room with a fireplace, comfortable furniture, and large windows\",\n",
    "    \"A lush tropical beach with palm trees, crystal clear water, and white sand\",\n",
    "    \"A futuristic city skyline at night with neon lights and flying vehicles\",\n",
    "    \"A dense forest with tall trees, sunlight filtering through the leaves, and a small stream\"\n",
    "]\n",
    "\n",
    "# Generate and visualize panoramas for each prompt\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    print(f\"Generating panorama for prompt: {prompt}\")\n",
    "    \n",
    "    # Generate panorama\n",
    "    panorama = pipeline.generate(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=\"low quality, blurry, distorted\",\n",
    "        num_inference_steps=30,  # Use fewer steps for faster inference during testing\n",
    "        guidance_scale=7.5,\n",
    "        height=512,\n",
    "        width=512,\n",
    "        output_type=\"pil\"\n",
    "    )\n",
    "    \n",
    "    # Display panorama\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.imshow(np.array(panorama))\n",
    "    plt.title(f\"Prompt: {prompt}\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save panorama\n",
    "    os.makedirs(\"../outputs/samples\", exist_ok=True)\n",
    "    panorama.save(f\"../outputs/samples/panorama_{i}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Cubemap Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a prompt to visualize individual cube faces\n",
    "test_prompt = \"A beautiful mountain landscape with a lake and forest in the foreground\"\n",
    "\n",
    "# Generate cubemap latents\n",
    "latents = pipeline.generate(\n",
    "    prompt=test_prompt,\n",
    "    negative_prompt=\"low quality, blurry, distorted\",\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    output_type=\"latent\"\n",
    ")\n",
    "\n",
    "# Extract and visualize individual faces\n",
    "face_names = ['front', 'right', 'back', 'left', 'top', 'bottom']\n",
    "cube_faces = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(6):\n",
    "        face_latent = latents[0, i].unsqueeze(0)  # Add batch dimension\n",
    "        face_image = pipeline.vae.decode(face_latent / 0.18215).sample\n",
    "        face_image = (face_image / 2 + 0.5).clamp(0, 1)\n",
    "        face_image = face_image[0].cpu().permute(1, 2, 0).numpy()\n",
    "        cube_faces.append(face_image)\n",
    "\n",
    "# Plot the cubemap faces\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for i, (face_name, face_img) in enumerate(zip(face_names, cube_faces)):\n",
    "    row, col = i // 3, i % 3\n",
    "    axs[row, col].imshow(face_img)\n",
    "    axs[row, col].set_title(face_name)\n",
    "    axs[row, col].axis('off')\n",
    "plt.suptitle(f\"Cubemap Faces for: {test_prompt}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Convert cubemap to equirectangular and visualize\n",
    "equirect = cubemap_to_equirect(np.array(cube_faces), 1024, 2048)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(equirect)\n",
    "plt.title(f\"Equirectangular Panorama: {test_prompt}\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Face Consistency and Stitching Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to check consistency across face boundaries\n",
    "def evaluate_face_consistency(cube_faces):\n",
    "    \"\"\"Evaluate the consistency between adjacent cube faces.\"\"\"\n",
    "    # Define adjacent face pairs to check\n",
    "    # Format: (face1_idx, face2_idx, face1_edge, face2_edge)\n",
    "    # Edges: 0=top, 1=right, 2=bottom, 3=left\n",
    "    adjacent_pairs = [\n",
    "        (0, 1, 1, 3),  # front-right\n",
    "        (1, 2, 1, 3),  # right-back\n",
    "        (2, 3, 1, 3),  # back-left\n",
    "        (3, 0, 1, 3),  # left-front\n",
    "        (0, 4, 0, 2),  # front-top\n",
    "        (0, 5, 2, 0),  # front-bottom\n",
    "        # Add more pairs as needed\n",
    "    ]\n",
    "    \n",
    "    # Calculate consistency scores\n",
    "    scores = []\n",
    "    \n",
    "    for face1_idx, face2_idx, face1_edge, face2_edge in adjacent_pairs:\n",
    "        face1 = cube_faces[face1_idx]\n",
    "        face2 = cube_faces[face2_idx]\n",
    "        \n",
    "        # Extract edge pixels from each face\n",
    "        if face1_edge == 0:  # Top edge\n",
    "            edge1 = face1[0, :, :]\n",
    "        elif face1_edge == 1:  # Right edge\n",
    "            edge1 = face1[:, -1, :]\n",
    "        elif face1_edge == 2:  # Bottom edge\n",
    "            edge1 = face1[-1, :, :]\n",
    "        else:  # Left edge\n",
    "            edge1 = face1[:, 0, :]\n",
    "        \n",
    "        if face2_edge == 0:  # Top edge\n",
    "            edge2 = face2[0, :, :]\n",
    "        elif face2_edge == 1:  # Right edge\n",
    "            edge2 = face2[:, -1, :]\n",
    "        elif face2_edge == 2:  # Bottom edge\n",
    "            edge2 = face2[-1, :, :]\n",
    "        else:  # Left edge\n",
    "            edge2 = face2[:, 0, :]\n",
    "        \n",
    "        # Ensure edges are in the same orientation\n",
    "        if (face1_edge + face2_edge) % 2 == 1:  # Perpendicular edges\n",
    "            edge2 = np.flip(edge2)\n",
    "        \n",
    "        # Calculate MSE between edges\n",
    "        mse = np.mean((edge1 - edge2) ** 2)\n",
    "        scores.append(mse)\n",
    "        \n",
    "    return scores\n",
    "\n",
    "# Evaluate consistency for the generated cubemap\n",
    "consistency_scores = evaluate_face_consistency(cube_faces)\n",
    "print(\"Face boundary consistency scores (MSE, lower is better):\")\n",
    "for i, score in enumerate(consistency_scores):\n",
    "    print(f\"Edge {i}: {score:.6f}\")\n",
    "\n",
    "print(f\"\\nAverage consistency score: {np.mean(consistency_scores):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare with Baseline Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For baseline comparison, we'll use a simple approach of generating multiple images and stitching them\n",
    "def generate_baseline_panorama(prompt):\n",
    "    \"\"\"Generate a baseline panorama by stitching individual images.\"\"\"\n",
    "    # Load standard Stable Diffusion pipeline\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\", \n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Generate 4 horizontal images with similar content\n",
    "    images = []\n",
    "    directions = [\"front view of\", \"right view of\", \"back view of\", \"left view of\"]\n",
    "    \n",
    "    for direction in directions:\n",
    "        full_prompt = f\"{direction} {prompt}\"\n",
    "        image = pipe(full_prompt, guidance_scale=7.5).images[0]\n",
    "        images.append(np.array(image))\n",
    "    \n",
    "    # Stitch images horizontally (very naive approach, just for demonstration)\n",
    "    stitched = np.concatenate(images, axis=1)\n",
    "    \n",
    "    return stitched\n",
    "\n",
    "# Generate and compare panoramas\n",
    "test_prompt = \"A mountain landscape with snow-capped peaks and green valleys\"\n",
    "\n",
    "# Generate CubeDiff panorama\n",
    "cubediff_panorama = pipeline.generate(\n",
    "    prompt=test_prompt,\n",
    "    negative_prompt=\"low quality, blurry, distorted\",\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    output_type=\"np\"\n",
    ")\n",
    "\n",
    "# Generate baseline panorama\n",
    "baseline_panorama = generate_baseline_panorama(test_prompt)\n",
    "\n",
    "# Visualize and compare\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(cubediff_panorama)\n",
    "plt.title(\"CubeDiff Panorama\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(baseline_panorama)\n",
    "plt.title(\"Baseline Panorama (Naive Stitching)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.suptitle(f\"Comparison for prompt: {test_prompt}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
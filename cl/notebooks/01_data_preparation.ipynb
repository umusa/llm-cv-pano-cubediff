{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CubeDiff: Data Preparation\n",
    "\n",
    "This notebook demonstrates the process of preparing panorama data for CubeDiff training.\n",
    "\n",
    "1. Download sample panoramas\n",
    "2. Convert equirectangular panoramas to cubemaps\n",
    "3. Visualize the data\n",
    "4. Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "# Add parent directory to path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import custom modules\n",
    "from data.preprocessing import equirect_to_cubemap, preprocess_panorama_dataset\n",
    "from data.dataset import CubemapDataset, get_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Sample Panoramas\n",
    "\n",
    "Let's download a few sample panoramas from Polyhaven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directories\n",
    "os.makedirs(\"../data/raw\", exist_ok=True)\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# Sample panorama URLs from Polyhaven\n",
    "sample_urls = [\n",
    "    \"https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/alps_field_2k.exr\",\n",
    "    \"https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/empty_warehouse_01_2k.exr\",\n",
    "    \"https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/sunflowers_2k.exr\",\n",
    "    \"https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/venetian_crossroads_2k.exr\",\n",
    "    \"https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/rural_asphalt_road_2k.exr\"\n",
    "]\n",
    "\n",
    "# Download panoramas\n",
    "for url in tqdm(sample_urls, desc=\"Downloading panoramas\"):\n",
    "    filename = os.path.basename(url)\n",
    "    filepath = os.path.join(\"../data/raw\", filename)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        response = requests.get(url, stream=True)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        # Convert EXR to JPG for easier handling\n",
    "        jpg_filepath = filepath.replace('.exr', '.jpg')\n",
    "        \n",
    "        # Use OpenCV to read and convert EXR\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        exr_img = cv2.imread(filepath, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)\n",
    "        \n",
    "        # Simple tone mapping for HDR to LDR conversion\n",
    "        exr_img = np.clip(exr_img * 0.5, 0, 1) * 255\n",
    "        exr_img = exr_img.astype(np.uint8)\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        exr_img = cv2.cvtColor(exr_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Save as JPG\n",
    "        Image.fromarray(exr_img).save(jpg_filepath)\n",
    "        print(f\"Converted {filename} to {os.path.basename(jpg_filepath)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the downloaded panoramas\n",
    "preprocess_panorama_dataset(\n",
    "    input_dir=\"../data/raw\",\n",
    "    output_dir=\"../data/processed/cubemaps\",\n",
    "    face_size=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample captions for the panoramas\n",
    "captions = {\n",
    "    \"alps_field\": \"A panoramic view of the Swiss Alps with green fields under a clear blue sky\",\n",
    "    \"empty_warehouse_01\": \"An empty industrial warehouse with concrete floors and metal beams\",\n",
    "    \"sunflowers\": \"A field of golden sunflowers stretching to the horizon under a sunny sky\",\n",
    "    \"venetian_crossroads\": \"A scenic Italian street intersection in Venice with historic buildings\",\n",
    "    \"rural_asphalt_road\": \"A rural asphalt road cutting through countryside fields\"\n",
    "}\n",
    "\n",
    "# Save captions to JSON file\n",
    "with open(\"../data/processed/captions.json\", \"w\") as f:\n",
    "    json.dump(captions, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize the Cubemap Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cubemap faces for one panorama\n",
    "sample_pano = \"sunflowers\"\n",
    "sample_pano_dir = os.path.join(\"../data/processed/cubemaps\", sample_pano)\n",
    "\n",
    "face_names = ['front', 'right', 'back', 'left', 'top', 'bottom']\n",
    "face_images = []\n",
    "\n",
    "for face_name in face_names:\n",
    "    face_path = os.path.join(sample_pano_dir, f\"{face_name}.jpg\")\n",
    "    face_img = Image.open(face_path)\n",
    "    face_images.append(np.array(face_img))\n",
    "\n",
    "# Plot the cubemap faces\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for i, (face_name, face_img) in enumerate(zip(face_names, face_images)):\n",
    "    row, col = i // 3, i % 3\n",
    "    axs[row, col].imshow(face_img)\n",
    "    axs[row, col].set_title(face_name)\n",
    "    axs[row, col].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the dataset\n",
    "test_dataset = CubemapDataset(\n",
    "    data_dir=\"../data/processed/cubemaps\",\n",
    "    captions_file=\"../data/processed/captions.json\"\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Get a sample\n",
    "sample = test_dataset[0]\n",
    "print(f\"Sample keys: {sample.keys()}\")\n",
    "print(f\"Faces tensor shape: {sample['faces'].shape}\")\n",
    "print(f\"Caption: {sample['caption']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sample\n",
    "faces = sample['faces']\n",
    "faces_np = faces.permute(0, 2, 3, 1).numpy() * 0.5 + 0.5\n",
    "faces_np = np.clip(faces_np, 0, 1)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for i, (face_name, face_img) in enumerate(zip(face_names, faces_np)):\n",
    "    row, col = i // 3, i % 3\n",
    "    axs[row, col].imshow(face_img)\n",
    "    axs[row, col].set_title(face_name)\n",
    "    axs[row, col].axis('off')\n",
    "plt.suptitle(f\"Caption: {sample['caption']}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the dataloader\n",
    "test_dataloader = get_dataloader(\n",
    "    data_dir=\"../data/processed/cubemaps\",\n",
    "    captions_file=\"../data/processed/captions.json\",\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "batch = next(iter(test_dataloader))\n",
    "print(f\"Batch keys: {batch.keys()}\")\n",
    "print(f\"Batch faces shape: {batch['faces'].shape}\")\n",
    "print(f\"Batch captions: {batch['caption']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Training and Validation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a real training scenario, create train/val splits\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# With a small dataset, we'll use a higher validation ratio for demonstration\n",
    "val_ratio = 0.2\n",
    "dataset_size = len(test_dataset)\n",
    "val_size = int(dataset_size * val_ratio)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "# Create random splits with a fixed seed for reproducibility\n",
    "train_dataset, val_dataset = random_split(\n",
    "    test_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"Full dataset size: {dataset_size}\")\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've successfully:\n",
    "1. Downloaded sample panoramas from Polyhaven\n",
    "2. Converted equirectangular panoramas to cubemap faces\n",
    "3. Created a dataset with captions\n",
    "4. Visualized the cubemap faces\n",
    "5. Tested the dataset and dataloader\n",
    "6. Created training and validation splits\n",
    "\n",
    "Next steps:\n",
    "1. Implement the CubeDiff model architecture\n",
    "2. Set up the training pipeline\n",
    "3. Train the model on this dataset\n",
    "4. Evaluate the results\n",
    "\n",
    "For a real training scenario, you would want to collect more panoramas to expand the dataset. The paper mentions using Polyhaven, SUN360, and other sources to build a larger dataset. Even with a small dataset, the LoRA fine-tuning approach should be able to produce decent results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}